I moved the objects to:
[5.8 4.8]
[2.3 5.4]
I moved the objects to:
[6.9 7.9]
[7.5 3.5]
I moved the objects to:
[3.1 2.2]
[4.8 4.7]
I moved the objects to:
[3.8 6.6]
[2.8 2.9]
I moved the objects to:
[6.5 6.2]
[3.7 7.6]
I moved the objects to:
[7.4 5.7]
[4.1 5.5]
I moved the objects to:
[7.2 4.6]
[4.4 7.6]
I moved the objects to:
[5.5 7.3]
[5.6 6.4]
I moved the objects to:
[6.9 2.5]
[7.8 6.4]
I moved the objects to:
[5.8 6.7]
[4.4 6.8]
I moved the objects to:
[6.3 2.9]
[5.  5.5]
I moved the objects to:
[7.3 7. ]
[2.9 5.3]
I moved the objects to:
[5.8 3.6]
[5.5 6.2]
I moved the objects to:
[4.2 4.5]
[3.9 2.2]
I moved the objects to:
[4.  4.6]
[2.7 6. ]
I moved the objects to:
[7.6 3.7]
[2.8 7.3]
I moved the objects to:
[3.2 5.3]
[2.7 2.3]
I moved the objects to:
[3.  7.4]
[6.5 2.5]
I moved the objects to:
[5.9 6.5]
[6.8 5.2]
I moved the objects to:
[5.8 2. ]
[4.  2.2]
I moved the objects to:
[5.9 3.1]
[2.4 5.1]
I moved the objects to:
[6.2 7.6]
[6.1 2. ]
I moved the objects to:
[6.7 2.4]
[6.9 6.2]
I moved the objects to:
[4.4 6.8]
[2.8 2.3]
I moved the objects to:
[2.2 7.1]
[3.4 5.8]
I moved the objects to:
[6.7 2.1]
[7.5 4.6]
I moved the objects to:
[4.1 2.7]
[7.6 5.5]
I moved the objects to:
[4.3 5.7]
[7.1 2.6]
I moved the objects to:
[6.5 7. ]
[5.1 2.4]
I moved the objects to:
[2.8 6.5]
[2.9 5.2]
I moved the objects to:
[3.8 5.6]
[5.1 3.4]
I moved the objects to:
[5.7 4.4]
[6.2 6.8]
I moved the objects to:
[7.4 3.8]
[3.7 6.5]
I moved the objects to:
[5.8 4.8]
[3.8 7.2]
I moved the objects to:
[5.9 2.2]
[5.9 5.4]
I moved the objects to:
[3.6 4.6]
[6.3 3.9]
I moved the objects to:
[7.2 3.6]
[5.2 3. ]
I moved the objects to:
[6.1 6. ]
[4.2 3.4]
I moved the objects to:
[4.6 6.1]
[2.1 4.5]
I moved the objects to:
[3.  5.9]
[2.2 5.7]
I moved the objects to:
[3.  6.3]
[6.7 2.3]
I moved the objects to:
[3.8 7.4]
[3.4 6.2]
I moved the objects to:
[3.5 7.6]
[4.7 7.2]
I moved the objects to:
[2.3 6.6]
[6.1 3.2]
I moved the objects to:
[7.4 3.4]
[4.9 3.2]
I moved the objects to:
[4.9 4.1]
[6.4 4.7]
I moved the objects to:
[6.6 7. ]
[3.5 7.4]
I moved the objects to:
[7.1 5.3]
[5.4 4.4]
I moved the objects to:
[7.5 5.8]
[6.5 7. ]
I moved the objects to:
[7.8 7.2]
[3.  6.3]
I moved the objects to:
[3.1 4.8]
[3.1 5.8]
I moved the objects to:
[7.2 4.4]
[7.3 5.4]
I moved the objects to:
[3.5 3.2]
[2.3 4.8]
C:\Users\tomda\anaconda3\Lib\site-packages\torchvision\transforms\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch 0, Loss 312.7988586425781, Accuracy 0.1875
C:\Users\tomda\anaconda3\Lib\site-packages\torchvision\transforms\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Test Loss 0.029494520276784897, Test Accuracy 0.22052173913043477
Epoch 1, Loss 0.7439368963241577, Accuracy 0.11875
Epoch 2, Loss 0.7135667204856873, Accuracy 0.15
Epoch 3, Loss 0.7340330481529236, Accuracy 0.12916666666666668
Epoch 4, Loss 0.7001715302467346, Accuracy 0.15
Epoch 5, Loss 0.6868362426757812, Accuracy 0.13958333333333334
Test Loss 0.03218052163720131, Test Accuracy 0.24542028985507247
Epoch 6, Loss 0.8583995699882507, Accuracy 0.19166666666666668
Epoch 7, Loss 0.6920484900474548, Accuracy 0.20208333333333334
Epoch 8, Loss 0.7617445588111877, Accuracy 0.20208333333333334
Epoch 9, Loss 0.6522891521453857, Accuracy 0.24375
Epoch 10, Loss 0.697382390499115, Accuracy 0.2125
Test Loss 0.030338412150740623, Test Accuracy 0.24407608695652172
Epoch 11, Loss 0.7279651165008545, Accuracy 0.13958333333333334
Epoch 12, Loss 0.7274191379547119, Accuracy 0.15
Epoch 13, Loss 0.71561199426651, Accuracy 0.15
Epoch 14, Loss 0.7949180006980896, Accuracy 0.11875
Epoch 15, Loss 0.7015239596366882, Accuracy 0.13958333333333334
Test Loss 0.029783593490719795, Test Accuracy 0.24658333333333335
Epoch 16, Loss 0.6671242117881775, Accuracy 0.2125
Epoch 17, Loss 0.7250290513038635, Accuracy 0.2125
Epoch 18, Loss 0.7247804403305054, Accuracy 0.2125
Epoch 19, Loss 0.8224193453788757, Accuracy 0.19166666666666668
Epoch 20, Loss 0.7677172422409058, Accuracy 0.20208333333333334
Test Loss 0.029707686975598335, Test Accuracy 0.2471268115942029
Epoch 21, Loss 0.7814754247665405, Accuracy 0.11875
Epoch 22, Loss 0.749364972114563, Accuracy 0.15
Epoch 23, Loss 0.723910927772522, Accuracy 0.13958333333333334
Epoch 24, Loss 0.6796913743019104, Accuracy 0.15
Epoch 25, Loss 0.742779016494751, Accuracy 0.13958333333333334
Test Loss 0.03357367217540741, Test Accuracy 0.23044202898550725
Epoch 26, Loss 0.7707292437553406, Accuracy 0.2125
Epoch 27, Loss 0.8286590576171875, Accuracy 0.18125
Epoch 28, Loss 0.8604174852371216, Accuracy 0.19166666666666668
Epoch 29, Loss 0.7239665985107422, Accuracy 0.2125
Epoch 30, Loss 0.7593064904212952, Accuracy 0.20208333333333334
Test Loss 0.030397914350032806, Test Accuracy 0.2506268115942029
Epoch 31, Loss 0.759931206703186, Accuracy 0.2125
Epoch 32, Loss 0.7397975921630859, Accuracy 0.20208333333333334
Epoch 33, Loss 0.7788881063461304, Accuracy 0.19166666666666668
Epoch 34, Loss 0.6995397806167603, Accuracy 0.22291666666666665
Epoch 35, Loss 0.7163006067276001, Accuracy 0.20208333333333334
Test Loss 0.03246627002954483, Test Accuracy 0.2506268115942029
Epoch 36, Loss 0.7749456763267517, Accuracy 0.18125
Epoch 37, Loss 0.7089657187461853, Accuracy 0.2125
Epoch 38, Loss 0.8277088403701782, Accuracy 0.2125
Epoch 39, Loss 0.7362219095230103, Accuracy 0.2125
Epoch 40, Loss 0.7823764085769653, Accuracy 0.19166666666666668
Test Loss 0.030540429055690765, Test Accuracy 0.25084057971014495
Traceback (most recent call last):
  File "C:\Users\tomda\Desktop\symmetry_learning\symmetry_shift_runner.py", line 51, in <module>
    main(config)
  File "C:\Users\tomda\Desktop\symmetry_learning\symmetry_shift_runner.py", line 36, in main
    bc_control(config)
  File "C:\Users\tomda\Desktop\symmetry_learning\symmetry_shift_runner.py", line 17, in bc_control
    bcRunner(env)
  File "C:\Users\tomda\Desktop\symmetry_learning\algos\bc.py", line 278, in bcRunner
    bc(env, model)
  File "C:\Users\tomda\Desktop\symmetry_learning\algos\bc.py", line 166, in bc
    for i, (states, actions) in enumerate(dataloader):
  File "C:\Users\tomda\anaconda3\Lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\tomda\anaconda3\Lib\site-packages\torch\utils\data\dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tomda\anaconda3\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\tomda\anaconda3\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\tomda\Desktop\symmetry_learning\algos\bc.py", line 45, in __getitem__
    image = torch.tensor(image)#.permute(1, 2, 0)
            ^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in: <module 'threading' from 'C:\\Users\\tomda\\anaconda3\\Lib\\threading.py'>
Traceback (most recent call last):
  File "C:\Users\tomda\anaconda3\Lib\threading.py", line 1556, in _shutdown
    if _main_thread.ident == get_ident():
       ^^^^^^^^^^^^^^^^^^
  File "C:\Users\tomda\anaconda3\Lib\threading.py", line 1161, in ident
    @property
KeyboardInterrupt: